## Visualization

* Olah, et al., "The Building Blocks of Interpretability", Distill, 2018. https://distill.pub/2018/building-blocks/
* Visualizing Representations: Deep Learning and Human Beings, Colah's Blog, http://colah.github.io/posts/2015-01-Visualizing-Representations/
* http://karpathy.github.io/2015/05/21/rnn-effectiveness/
* http://deeplearning.csail.mit.edu/presentation_tutorial_interpretability_slide.pdf
* Opening the Black Box of Deep Neural Networks via Information, Ravid Shwartz-Ziv, Naftali Tishby. [arXiv:1703.00810](https://arxiv.org/abs/1703.00810)
* Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman. [arXiv:1312.6034](https://arxiv.org/abs/1312.6034)

## Sensitivity and Relevance Analysis
* Explaining NonLinear Classification Decisions with Deep Taylor Decomposition, Grégoire Montavon, Sebastian Bach, Alexander Binder, Wojciech Samek, Klaus-Robert Müller. [arXiv:1512.02479](https://arxiv.org/abs/1512.02479)


# Conferences

* [Uncertainty and Robustness in Deep Learning, ICML2019 Workshop](https://icml.cc/Conferences/2019/ScheduleMultitrack?event=3514)
* [ICLR2019](https://iclr.cc/)
* [NeurIPS2018](https://nips.cc/Conferences/2018) [[Summary Notes]](https://taolicheng.github.io/understanding-dnn/?p=NIPS2018_Summary_UdeM.md)
  * *Workshop* [Bayesian Deep Learning](http://bayesiandeeplearning.org/)
  * *Workshop* [Causal Learning](https://sites.google.com/view/nips2018causallearning/home)
  * *Workshop* [Interpretability and Robustness in Audio, Speech, and Language](https://irasl.gitlab.io/)
